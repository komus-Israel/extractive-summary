{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk import WordNetLemmatizer\n",
    "from PyPDF2 import PdfFileWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cal_thres.txt', 'r') as file:\n",
    "    doc = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Removal of special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = doc.replace('.', '. ')\n",
    "tokenize_sent = sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(doc):\n",
    "    regex = r'[^a-zA-Z0-9\\s]'\n",
    "    text_ = [re.sub(regex, '', i) for i in tokenize_sent]\n",
    "    return text_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    tokens = [word for sent in sent_tokenize(text) for word in word_tokenize(sent)]\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    new_tokens = [i for i in tokens if i not in stopwords.words('english')]\n",
    "    tokens = [word for word in new_tokens if len(word) >= 3]\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    tagged_corpus = pos_tag(tokens)\n",
    "\n",
    "    Noun_tags = ['NN', 'NNP', 'NNPS', 'NNS']\n",
    "    verb_tags = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def prac_lemmatize(token, tag):\n",
    "        if tag in Noun_tags:\n",
    "            return lemmatizer.lemmatize(token, 'n')\n",
    "        elif tag in verb_tags:\n",
    "            return lemmatizer.lemmatize(token, 'v')\n",
    "        else:\n",
    "            return lemmatizer.lemmatize(token, 'n')\n",
    "    lemmatized_text = ' '.join([prac_lemmatize(token, tag) for token, tag in tagged_corpus])\n",
    "    \n",
    "    return lemmatized_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text_):    \n",
    "    final_text = np.array([text_preprocessing(i) for i in text_])\n",
    "    vectorizer = TfidfVectorizer(strip_accents = 'unicode', norm = 'l2')\n",
    "\n",
    "    matrix = vectorizer.fit_transform(final_text).todense()\n",
    "\n",
    "    sent_score = matrix.sum(axis=1)\n",
    "\n",
    "    sent_score_total = sent_score.sum()\n",
    "\n",
    "    average = sent_score_total/sent_score.shape[0]\n",
    "\n",
    "    summary = []\n",
    "\n",
    "    for i in range(sent_score.shape[0]):\n",
    "        if sent_score[i] >= average:\n",
    "            summary.append(tokenize_sent[i])\n",
    "    \n",
    "    return ''.join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Using the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = regex(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = [text_preprocessing(i) for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_text = summarize(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2054"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Needful to say, i can be very pragmatic in my thinking, introvert, inspiring and convincing\\n\\n#thinking style: this result shows that i'm more pragmatic in my thinking, offering logical and approachable way to solve issues and view situations beyond theories.one of my approach to issues that defines me as an Advocate is concrete steps to implementing solutions, which as an optimizer, I adopt in my thinking,finding ways to be more productive, efficient and organized.#team role test: For every time I get the chance to participate in a team work, I tend to discover I am able to express a good interpersonal skills and some basic soft skills, yet learning.It also show that I can commuunicate effectively and resolve conflict with team mates\\n\\n#team role pie chart: this chart shows that I'm more of an executive and innovator characterised by my eagerness to get the work organized and done.Also as the creative generator of a team, strong imagination and desire to be original defines me as an innovator also as an Advocate.Needful to say, i can be very pragmatic in my thinking, introvert, inspiring and convincing\\n\\n#thinking style: this result shows that i'm more pragmatic in my thinking, offering logical and approachable way to solve issues and view situations beyond theories.one of my approach to issues that defines me as an Advocate is concrete steps to implementing solutions, which as an optimizer, I adopt in my thinking,finding ways to be more productive, efficient and organized.#team role test: For every time I get the chance to participate in a team work, I tend to discover I am able to express a good interpersonal skills and some basic soft skills, yet learning.It also show that I can commuunicate effectively and resolve conflict with team mates\\n\\n#team role pie chart: this chart shows that I'm more of an executive and innovator characterised by my eagerness to get the work organized and done.Also as the creative generator of a team, strong imagination and desire to be original defines me as an innovator also as an Advocate.\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sum2.txt', 'w') as file:\n",
    "    file.write(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
